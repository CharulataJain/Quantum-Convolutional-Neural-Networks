{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads and Processes the data that will be used in QCNN and Hierarchical Classifier Training\n",
    "pca32 = ['pca32-1', 'pca32-2', 'pca32-3', 'pca32-4']\n",
    "autoencoder32 = ['autoencoder32-1', 'autoencoder32-2', 'autoencoder32-3', 'autoencoder32-4']\n",
    "pca30 = ['pca30-1', 'pca30-2', 'pca30-3', 'pca30-4']\n",
    "autoencoder30 = ['autoencoder30-1', 'autoencoder30-2', 'autoencoder30-3', 'autoencoder30-4']\n",
    "pca16 = ['pca16-1', 'pca16-2', 'pca16-3', 'pca16-4', 'pca16-compact']\n",
    "autoencoder16 = ['autoencoder16-1', 'autoencoder16-2', 'autoencoder16-3', 'autoencoder16-4', 'autoencoder16-compact']\n",
    "pca12 = ['pca12-1', 'pca12-2', 'pca12-3', 'pca12-4']\n",
    "autoencoder12 = ['autoencoder12-1', 'autoencoder12-2', 'autoencoder12-3', 'autoencoder12-4']\n",
    "\n",
    "def data_load_and_process(dataset, classes=[0, 1], feature_reduction='resize256', binary=True):\n",
    "    if dataset == 'fashion_mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    elif dataset == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
    "\n",
    "    if classes == 'odd_even':\n",
    "        odd = [1, 3, 5, 7, 9]\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y in odd else 0 for y in y_train]\n",
    "            Y_test = [1 if y in odd else 0 for y in y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y in odd else -1 for y in y_train]\n",
    "            Y_test = [1 if y in odd else -1 for y in y_test]\n",
    "\n",
    "    elif classes == '>4':\n",
    "        greater = [5, 6, 7, 8, 9]\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y in greater else 0 for y in y_train]\n",
    "            Y_test = [1 if y in greater else 0 for y in y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y in greater else -1 for y in y_train]\n",
    "            Y_test = [1 if y in greater else -1 for y in y_test]\n",
    "\n",
    "    else:\n",
    "        x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
    "        x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
    "\n",
    "        X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "        Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
    "\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y == classes[0] else 0 for y in Y_train]\n",
    "            Y_test = [1 if y == classes[0] else 0 for y in Y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y == classes[0] else -1 for y in Y_train]\n",
    "            Y_test = [1 if y == classes[0] else -1 for y in Y_test]\n",
    "\n",
    "    if feature_reduction == 'resize256':\n",
    "        X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
    "        X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
    "        X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    elif feature_reduction == 'pca8' or feature_reduction in pca32 \\\n",
    "            or feature_reduction in pca30 or feature_reduction in pca16 or feature_reduction in pca12:\n",
    "\n",
    "        X_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
    "        X_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
    "        X_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
    "\n",
    "        if feature_reduction == 'pca8':\n",
    "            pca = PCA(8)\n",
    "        elif feature_reduction in pca32:\n",
    "            pca = PCA(32)\n",
    "        elif feature_reduction in pca30:\n",
    "            pca = PCA(30)\n",
    "        elif feature_reduction in pca16:\n",
    "            pca = PCA(16)\n",
    "        elif feature_reduction in pca12:\n",
    "            pca = PCA(12)\n",
    "\n",
    "\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "        # Rescale for angle embedding\n",
    "        if feature_reduction == 'pca8' or feature_reduction == 'pca16-compact' or \\\n",
    "                feature_reduction in pca30 or feature_reduction in pca12:\n",
    "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())),\\\n",
    "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    elif feature_reduction == 'autoencoder8' or feature_reduction in autoencoder32 \\\n",
    "            or feature_reduction in autoencoder30 or feature_reduction in autoencoder16 or feature_reduction in autoencoder12:\n",
    "        if feature_reduction == 'autoencoder8':\n",
    "            latent_dim = 8\n",
    "        elif feature_reduction in autoencoder32:\n",
    "            latent_dim = 32\n",
    "        elif feature_reduction in autoencoder30:\n",
    "            latent_dim = 30\n",
    "        elif feature_reduction in autoencoder16:\n",
    "            latent_dim = 16\n",
    "        elif feature_reduction in autoencoder12:\n",
    "            latent_dim = 12\n",
    "\n",
    "\n",
    "\n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim\n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                    layers.Dense(784, activation='sigmoid'),\n",
    "                    layers.Reshape((28, 28))\n",
    "                ])\n",
    "\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "\n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(X_train, X_train,\n",
    "                        epochs=10,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_test, X_test))\n",
    "\n",
    "        X_train, X_test = autoencoder.encoder(X_train).numpy(), autoencoder.encoder(X_test).numpy()\n",
    "\n",
    "        # Rescale for Angle Embedding\n",
    "        # Note this is not a rigorous rescaling method\n",
    "        if feature_reduction == 'autoencoder8' or feature_reduction == 'autoencoder16-compact' or\\\n",
    "                feature_reduction in autoencoder30 or feature_reduction in autoencoder12:\n",
    "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())), \\\n",
    "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unitaries for convolution and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This module contains the set of unitary ansatze that will be used to benchmark the performances of Quantum Convolutional Neural Network (QCNN) in QCNN.ipynb module\n",
    "import pennylane as qml\n",
    "\n",
    "# Unitary Ansatze for Convolutional Layer\n",
    "def U_TTN(params, wires):  # 2 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_5(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_6(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRX(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_9(params, wires):  # 2 params\n",
    "    qml.Hadamard(wires=wires[0])\n",
    "    qml.Hadamard(wires=wires[1])\n",
    "    qml.CZ(wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_13(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_14(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRX(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_15(params, wires):  # 4 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_SO4(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[4], wires=wires[0])\n",
    "    qml.RY(params[5], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_SU4(params, wires): # 15 params\n",
    "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
    "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[6], wires=wires[0])\n",
    "    qml.RZ(params[7], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[8], wires=wires[0])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
    "    qml.U3(params[12], params[13], params[14], wires=wires[1])\n",
    "\n",
    "# Pooling Layer\n",
    "\n",
    "def Pooling_ansatz1(params, wires): #2 params\n",
    "    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRX(params[1], wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz2(wires): #0 params\n",
    "    qml.CRZ(wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz3(*params, wires): #3 params\n",
    "    qml.CRot(*params, wires=[wires[0], wires[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an implementation of data_embedding function used for 8 qubits Quantum Convolutional Neural Network (QCNN)\n",
    "# and Hierarchical Quantum Classifier circuit.\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
    "from pennylane.templates.state_preparations import MottonenStatePreparation\n",
    "import numpy as np\n",
    "from Angular_hybrid import Angular_Hybrid_4, Angular_Hybrid_2\n",
    "def data_embedding(X, embedding_type='Amplitude'):\n",
    "    if embedding_type == 'Amplitude':\n",
    "        AmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
    "    elif embedding_type == 'Angle':\n",
    "        AngleEmbedding(X, wires=range(8), rotation='Y')\n",
    "    elif embedding_type == 'Angle-compact':\n",
    "        AngleEmbedding(X[:8], wires=range(8), rotation='X')\n",
    "        AngleEmbedding(X[8:16], wires=range(8), rotation='Y')\n",
    "\n",
    "    # Hybrid Direct Embedding (HDE)\n",
    "    elif embedding_type == 'Amplitude-Hybrid4-1' or embedding_type == 'Amplitude-Hybrid4-2' or \\\n",
    "            embedding_type == 'Amplitude-Hybrid4-3' or embedding_type == 'Amplitude-Hybrid4-4':\n",
    "        X1 = X[:2 ** 4]\n",
    "        X2 = X[2 ** 4:2 ** 5]\n",
    "        norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
    "        X1, X2 = X1 / norm_X1, X2 / norm_X2\n",
    "\n",
    "        if embedding_type == 'Amplitude-Hybrid4-1':\n",
    "            MottonenStatePreparation(X1, wires=[0, 1, 2, 3])\n",
    "            MottonenStatePreparation(X2, wires=[4, 5, 6, 7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-2':\n",
    "            MottonenStatePreparation(X1, wires=[0, 2, 4, 6])\n",
    "            MottonenStatePreparation(X2, wires=[1, 3, 5, 7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-3':\n",
    "            MottonenStatePreparation(X1, wires=[0, 1, 6, 7])\n",
    "            MottonenStatePreparation(X2, wires=[2, 3, 4, 5])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-4':\n",
    "            MottonenStatePreparation(X1, wires=[0, 3, 4, 7])\n",
    "            MottonenStatePreparation(X2, wires=[1, 2, 5, 6])\n",
    "\n",
    "    elif embedding_type == 'Amplitude-Hybrid2-1' or embedding_type == 'Amplitude-Hybrid2-2' \\\n",
    "            or embedding_type == 'Amplitude-Hybrid2-3' or embedding_type == 'Amplitude-Hybrid2-4':\n",
    "        X1 = X[:4]\n",
    "        X2 = X[4:8]\n",
    "        X3 = X[8:12]\n",
    "        X4 = X[12:16]\n",
    "        norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(X3), np.linalg.norm(\n",
    "            X4)\n",
    "        X1, X2, X3, X4 = X1 / norm_X1, X2 / norm_X2, X3 / norm_X3, X4 / norm_X4\n",
    "\n",
    "        if embedding_type == 'Amplitude-Hybrid2-1':\n",
    "            MottonenStatePreparation(X1, wires=[0,1])\n",
    "            MottonenStatePreparation(X2, wires=[2,3])\n",
    "            MottonenStatePreparation(X3, wires=[4,5])\n",
    "            MottonenStatePreparation(X4, wires=[6,7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-2':\n",
    "            MottonenStatePreparation(X1, wires=[0,4])\n",
    "            MottonenStatePreparation(X2, wires=[1,5])\n",
    "            MottonenStatePreparation(X3, wires=[2,6])\n",
    "            MottonenStatePreparation(X4, wires=[3,7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-3':\n",
    "            MottonenStatePreparation(X1, wires=[0,7])\n",
    "            MottonenStatePreparation(X2, wires=[1,6])\n",
    "            MottonenStatePreparation(X3, wires=[2,5])\n",
    "            MottonenStatePreparation(X4, wires=[3,4])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-4':\n",
    "            MottonenStatePreparation(X1, wires=[0,2])\n",
    "            MottonenStatePreparation(X2, wires=[1,3])\n",
    "            MottonenStatePreparation(X3, wires=[4,6])\n",
    "            MottonenStatePreparation(X4, wires=[5,7])\n",
    "\n",
    "    # Hybrid Angle Embedding (HAE)\n",
    "    elif embedding_type == 'Angular-Hybrid4-1' or embedding_type == 'Angular-Hybrid4-2' or \\\n",
    "            embedding_type == 'Angular-Hybrid4-3' or embedding_type == 'Angular-Hybrid4-4':\n",
    "        N = 15 # 15 classical data in 4 qubits\n",
    "        X1 = X[:N]\n",
    "        X2 = X[N:2*N]\n",
    "\n",
    "        if embedding_type == 'Angular-Hybrid4-1':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 1, 2, 3])\n",
    "            Angular_Hybrid_4(X2, wires=[4, 5, 6, 7])\n",
    "        elif embedding_type == 'Angular-Hybrid4-2':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 2, 4, 6])\n",
    "            Angular_Hybrid_4(X2, wires=[1, 3, 5, 7])\n",
    "        elif embedding_type == 'Angular-Hybrid4-3':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 1, 6, 7])\n",
    "            Angular_Hybrid_4(X2, wires=[2, 3, 4, 5])\n",
    "        elif embedding_type == 'Angular-Hybrid4-4':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 3, 4, 7])\n",
    "            Angular_Hybrid_4(X2, wires=[1, 2, 5, 6])\n",
    "\n",
    "    elif embedding_type == 'Angular-Hybrid2-1' or embedding_type == 'Angular-Hybrid2-2' \\\n",
    "            or embedding_type == 'Angular-Hybrid2-3' or embedding_type == 'Angular-Hybrid2-4':\n",
    "        N = 3  # 3 classical bits in 2 qubits\n",
    "        X1 = X[:N]\n",
    "        X2 = X[N:2*N]\n",
    "        X3 = X[2*N:3*N]\n",
    "        X4 = X[3*N:4*N]\n",
    "\n",
    "        if embedding_type == 'Angular-Hybrid2-1':\n",
    "            Angular_Hybrid_2(X1, wires=[0,1])\n",
    "            Angular_Hybrid_2(X2, wires=[2,3])\n",
    "            Angular_Hybrid_2(X3, wires=[4,5])\n",
    "            Angular_Hybrid_2(X4, wires=[6,7])\n",
    "        elif embedding_type == 'Angular-Hybrid2-2':\n",
    "            Angular_Hybrid_2(X1, wires=[0,4])\n",
    "            Angular_Hybrid_2(X2, wires=[1,5])\n",
    "            Angular_Hybrid_2(X3, wires=[2,6])\n",
    "            Angular_Hybrid_2(X4, wires=[3,7])\n",
    "        elif embedding_type == 'Angular-Hybrid2-3':\n",
    "            Angular_Hybrid_2(X1, wires=[0,7])\n",
    "            Angular_Hybrid_2(X2, wires=[1,6])\n",
    "            Angular_Hybrid_2(X3, wires=[2,5])\n",
    "            Angular_Hybrid_2(X4, wires=[3,4])\n",
    "        elif embedding_type == 'Angular-Hybrid2-4':\n",
    "            Angular_Hybrid_2(X1, wires=[0,2])\n",
    "            Angular_Hybrid_2(X2, wires=[1,3])\n",
    "            Angular_Hybrid_2(X3, wires=[4,6])\n",
    "            Angular_Hybrid_2(X4, wires=[5,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an implementation of an alternative Mottonen State Preparation to avoid normalization problem.\n",
    "import pennylane as qml\n",
    "\n",
    "# 3 bits of information is embedded in 2 wires\n",
    "def Angular_Hybrid_2(X, wires):\n",
    "    qml.RY(X[0], wires=wires[0])\n",
    "\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
    "\n",
    "# 15 bits of information is embedded in 4 wires\n",
    "def Angular_Hybrid_4(X, wires):\n",
    "    qml.RY(X[0], wires=wires[0])\n",
    "\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
    "\n",
    "    qml.RY(X[3], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[4], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "    qml.RY(X[5], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[6], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "\n",
    "    qml.RY(X[7], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[8], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[9], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[10], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])\n",
    "    qml.RY(X[11], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[12], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[13], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[14], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Implementation of Quantum circuit training procedure\n",
    "import QCNN_circuit\n",
    "import Hierarchical_circuit\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import autograd.numpy as anp\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def cross_entropy(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        c_entropy = l * (anp.log(p[l])) + (1 - l) * anp.log(1 - p[1 - l])\n",
    "        loss = loss + c_entropy\n",
    "    return -1 * loss\n",
    "\n",
    "def cost(params, X, Y, U, U_params, embedding_type, circuit, cost_fn):\n",
    "    if circuit == 'QCNN':\n",
    "        predictions = [QCNN_circuit.QCNN(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
    "    elif circuit == 'Hierarchical':\n",
    "        predictions = [Hierarchical_circuit.Hierarchical_classifier(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
    "\n",
    "    if cost_fn == 'mse':\n",
    "        loss = square_loss(Y, predictions)\n",
    "    elif cost_fn == 'cross_entropy':\n",
    "        loss = cross_entropy(Y, predictions)\n",
    "    return loss\n",
    "\n",
    "# Circuit training parameters\n",
    "steps = 200\n",
    "learning_rate = 0.01\n",
    "batch_size = 25\n",
    "def circuit_training(X_train, Y_train, U, U_params, embedding_type, circuit, cost_fn):\n",
    "    if circuit == 'QCNN':\n",
    "        if U == 'U_SU4_no_pooling' or U == 'U_SU4_1D' or U == 'U_9_1D':\n",
    "            total_params = U_params * 3\n",
    "        else:\n",
    "            total_params = U_params * 3 + 2 * 3\n",
    "    elif circuit == 'Hierarchical':\n",
    "        total_params = U_params * 7\n",
    "\n",
    "    params = np.random.randn(total_params, requires_grad=True)\n",
    "    opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    for it in range(steps):\n",
    "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "        X_batch = [X_train[i] for i in batch_index]\n",
    "        Y_batch = [Y_train[i] for i in batch_index]\n",
    "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit, cost_fn),\n",
    "                                                     params)\n",
    "        loss_history.append(cost_new)\n",
    "        if it % 10 == 0:\n",
    "            print(\"iteration: \", it, \" cost: \", cost_new)\n",
    "    return loss_history, params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4 resize256 with cross_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\autograd\\numpy\\numpy_vjps.py:698: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  onp.add.at(A, idx, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  17.763103316895773\n",
      "iteration:  10  cost:  11.143269960516378\n",
      "iteration:  20  cost:  9.854063822422795\n",
      "iteration:  30  cost:  6.983841829351263\n",
      "iteration:  40  cost:  10.37592658032676\n",
      "iteration:  50  cost:  10.31319865455306\n",
      "iteration:  60  cost:  7.61403394144802\n",
      "iteration:  70  cost:  8.818578948875448\n",
      "iteration:  80  cost:  6.783802543534079\n",
      "iteration:  90  cost:  9.433327425497033\n",
      "iteration:  100  cost:  8.317062710257423\n",
      "iteration:  110  cost:  8.749778629604089\n",
      "iteration:  120  cost:  10.118947808711532\n",
      "iteration:  130  cost:  12.352591794987898\n",
      "iteration:  140  cost:  9.661874751648133\n",
      "iteration:  150  cost:  5.397174146246707\n",
      "iteration:  160  cost:  8.002155600117316\n",
      "iteration:  170  cost:  10.442267033234078\n",
      "iteration:  180  cost:  9.638059910596736\n",
      "iteration:  190  cost:  8.30956661455318\n",
      "Accuracy for U_SU4 resize256 :0.888\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  16.943367526721836\n",
      "iteration:  10  cost:  14.990643011621858\n",
      "iteration:  20  cost:  15.90266406644366\n",
      "iteration:  30  cost:  6.446296083515172\n",
      "iteration:  40  cost:  8.47340070330526\n",
      "iteration:  50  cost:  10.714598790263302\n",
      "iteration:  60  cost:  9.583103774283195\n",
      "iteration:  70  cost:  7.514378868948263\n",
      "iteration:  80  cost:  6.793004991524817\n",
      "iteration:  90  cost:  8.474695033239497\n",
      "iteration:  100  cost:  10.492184236549136\n",
      "iteration:  110  cost:  9.46102569553543\n",
      "iteration:  120  cost:  9.52713977305952\n",
      "iteration:  130  cost:  9.217618433497812\n",
      "iteration:  140  cost:  7.308721003459437\n",
      "iteration:  150  cost:  8.628238986574948\n",
      "iteration:  160  cost:  7.901993568271634\n",
      "iteration:  170  cost:  6.90494451707459\n",
      "iteration:  180  cost:  8.366356859663078\n",
      "iteration:  190  cost:  8.107001382010498\n",
      "Accuracy for U_SU4_1D resize256 :0.9055\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_no_pooling resize256 with cross_entropy\n",
      "iteration:  0  cost:  16.612344272568276\n",
      "iteration:  10  cost:  12.466674634159359\n",
      "iteration:  20  cost:  10.133942325784762\n",
      "iteration:  30  cost:  9.680468443196967\n",
      "iteration:  40  cost:  11.598499167335063\n",
      "iteration:  50  cost:  7.448314334517503\n",
      "iteration:  60  cost:  7.7545084651191445\n",
      "iteration:  70  cost:  7.5863496894036295\n",
      "iteration:  80  cost:  11.22581654661862\n",
      "iteration:  90  cost:  7.22373543356298\n",
      "iteration:  100  cost:  9.497257013377961\n",
      "iteration:  110  cost:  7.533277582229065\n",
      "iteration:  120  cost:  9.694900202672251\n",
      "iteration:  130  cost:  10.90031680884171\n",
      "iteration:  140  cost:  9.542489211153047\n",
      "iteration:  150  cost:  7.719005188184794\n",
      "iteration:  160  cost:  9.841397431908835\n",
      "iteration:  170  cost:  7.320735598283638\n",
      "iteration:  180  cost:  11.57553531940404\n",
      "iteration:  190  cost:  7.98427387345514\n",
      "Accuracy for U_SU4_no_pooling resize256 :0.882\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  17.24878886169705\n",
      "iteration:  10  cost:  16.967901729625172\n",
      "iteration:  20  cost:  15.399581888246658\n",
      "iteration:  30  cost:  16.748782495239325\n",
      "iteration:  40  cost:  16.376990740440903\n",
      "iteration:  50  cost:  16.182311546089903\n",
      "iteration:  60  cost:  16.652656722940154\n",
      "iteration:  70  cost:  16.805845468507556\n",
      "iteration:  80  cost:  16.79944926011026\n",
      "iteration:  90  cost:  16.901797756294705\n",
      "iteration:  100  cost:  17.360443620898785\n",
      "iteration:  110  cost:  15.080445518424305\n",
      "iteration:  120  cost:  15.485638899848643\n",
      "iteration:  130  cost:  15.988771221398094\n",
      "iteration:  140  cost:  17.64582694287027\n",
      "iteration:  150  cost:  16.87189437615517\n",
      "iteration:  160  cost:  17.612267315892186\n",
      "iteration:  170  cost:  16.622412727387932\n",
      "iteration:  180  cost:  15.964383937495144\n",
      "iteration:  190  cost:  16.620904992012786\n",
      "Accuracy for U_9_1D resize256 :0.661\n"
     ]
    }
   ],
   "source": [
    "# This generates the results of the bechmarking code\n",
    "\n",
    "import Benchmarking\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here are possible combinations of benchmarking user could try.\n",
    "Unitaries: ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4', 'U_SU4', 'U_SU4_no_pooling', 'U_SU4_1D', 'U_9_1D']\n",
    "U_num_params: [2, 10, 10, 2, 6, 6, 4, 6, 15, 15, 15, 2]\n",
    "Encodings: ['resize256', 'pca8', 'autoencoder8', 'pca16-compact', 'autoencoder16-compact', 'pca32-1', 'autoencoder32-1',\n",
    "            'pca16-1', 'autoencoder16-1', 'pca30-1', 'autoencoder30-1', 'pca12-1', 'autoencoder12-1']\n",
    "dataset: 'mnist' or 'fashion_mnist'\n",
    "circuit: 'QCNN' or 'Hierarchical'\n",
    "cost_fn: 'mse' or 'cross_entropy'\n",
    "Note: when using 'mse' as cost_fn binary=\"True\" is recommended, when using 'cross_entropy' as cost_fn must be binary=\"False\".\n",
    "\"\"\"\n",
    "\n",
    "Unitaries = ['U_SU4', 'U_SU4_1D', 'U_SU4_no_pooling', 'U_9_1D']\n",
    "U_num_params = [15, 15, 15, 2]\n",
    "Encodings = ['resize256']\n",
    "dataset = 'fashion_mnist'\n",
    "classes = [0,1]\n",
    "binary = False\n",
    "cost_fn = 'cross_entropy'\n",
    "\n",
    "Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
    "#Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='Hierarchical', cost_fn=cost_fn, binary=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4 resize256 with cross_entropy\n",
      "iteration:  0  cost:  15.918992288963851\n",
      "iteration:  10  cost:  9.030952148181242\n",
      "iteration:  20  cost:  7.785021804956003\n",
      "iteration:  30  cost:  7.658499126216964\n",
      "iteration:  40  cost:  6.864304884165553\n",
      "iteration:  50  cost:  6.131326840920152\n",
      "iteration:  60  cost:  6.3054139264008295\n",
      "iteration:  70  cost:  4.835127127471202\n",
      "iteration:  80  cost:  4.294759967188206\n",
      "iteration:  90  cost:  3.891227549018417\n",
      "iteration:  100  cost:  5.916570587175542\n",
      "iteration:  110  cost:  6.798502075365489\n",
      "iteration:  120  cost:  5.709347778977407\n",
      "iteration:  130  cost:  5.322355127077859\n",
      "iteration:  140  cost:  5.205473022723898\n",
      "iteration:  150  cost:  7.140089448041656\n",
      "iteration:  160  cost:  5.832256902065695\n",
      "iteration:  170  cost:  5.85617506933688\n",
      "iteration:  180  cost:  6.612807268026101\n",
      "iteration:  190  cost:  4.382285400462807\n",
      "Accuracy for U_SU4 resize256 :0.9877068557919622\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  17.107859641526\n",
      "iteration:  10  cost:  12.478626881514723\n",
      "iteration:  20  cost:  12.840183643350672\n",
      "iteration:  30  cost:  13.765049614109845\n",
      "iteration:  40  cost:  10.901119213674429\n",
      "iteration:  50  cost:  13.174534151913498\n",
      "iteration:  60  cost:  13.281283306983246\n",
      "iteration:  70  cost:  11.01787150448765\n",
      "iteration:  80  cost:  13.265617706846871\n",
      "iteration:  90  cost:  12.346413569109501\n",
      "iteration:  100  cost:  10.282872445294078\n",
      "iteration:  110  cost:  12.323663747353308\n",
      "iteration:  120  cost:  15.002317991925441\n",
      "iteration:  130  cost:  12.488142045025361\n",
      "iteration:  140  cost:  12.84692133349695\n",
      "iteration:  150  cost:  11.59116335422063\n",
      "iteration:  160  cost:  10.424414219662506\n",
      "iteration:  170  cost:  11.183578079665953\n",
      "iteration:  180  cost:  7.176436685892203\n",
      "iteration:  190  cost:  10.798325648266829\n",
      "Accuracy for U_SU4_1D resize256 :0.9801418439716312\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_no_pooling resize256 with cross_entropy\n",
      "iteration:  0  cost:  18.39400642141189\n",
      "iteration:  10  cost:  11.138160468766028\n",
      "iteration:  20  cost:  10.089645222539701\n",
      "iteration:  30  cost:  9.468169287121238\n",
      "iteration:  40  cost:  8.403204922222738\n",
      "iteration:  50  cost:  8.295271791883302\n",
      "iteration:  60  cost:  10.069956202676922\n",
      "iteration:  70  cost:  8.177642859028623\n",
      "iteration:  80  cost:  6.700430664252019\n",
      "iteration:  90  cost:  8.171340066026517\n",
      "iteration:  100  cost:  7.739872726167336\n",
      "iteration:  110  cost:  8.55365168289998\n",
      "iteration:  120  cost:  7.9583068363641125\n",
      "iteration:  130  cost:  7.765513424781267\n",
      "iteration:  140  cost:  8.000957837776044\n",
      "iteration:  150  cost:  8.574342160425525\n",
      "iteration:  160  cost:  6.358221358890604\n",
      "iteration:  170  cost:  7.062508977577383\n",
      "iteration:  180  cost:  8.278754240651537\n",
      "iteration:  190  cost:  8.72680066159727\n",
      "Accuracy for U_SU4_no_pooling resize256 :0.9773049645390071\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  17.264892421630318\n",
      "iteration:  10  cost:  17.131905898679243\n",
      "iteration:  20  cost:  16.89111582657937\n",
      "iteration:  30  cost:  16.597646419458798\n",
      "iteration:  40  cost:  16.572153737199002\n",
      "iteration:  50  cost:  16.16596122423922\n",
      "iteration:  60  cost:  16.312755724943035\n",
      "iteration:  70  cost:  17.217052547801206\n",
      "iteration:  80  cost:  15.292521359695316\n",
      "iteration:  90  cost:  15.701657768397853\n",
      "iteration:  100  cost:  16.969755177366856\n",
      "iteration:  110  cost:  16.204501853345825\n",
      "iteration:  120  cost:  16.26432800552255\n",
      "iteration:  130  cost:  15.122327885183388\n",
      "iteration:  140  cost:  16.373976510329236\n",
      "iteration:  150  cost:  16.282956254559814\n",
      "iteration:  160  cost:  16.38584881714224\n",
      "iteration:  170  cost:  15.732912268238966\n",
      "iteration:  180  cost:  15.344624910172131\n",
      "iteration:  190  cost:  15.939179660674714\n",
      "Accuracy for U_9_1D resize256 :0.7361702127659574\n"
     ]
    }
   ],
   "source": [
    "# This generates the results of the bechmarking code\n",
    "\n",
    "import Benchmarking\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here are possible combinations of benchmarking user could try.\n",
    "Unitaries: ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4', 'U_SU4', 'U_SU4_no_pooling', 'U_SU4_1D', 'U_9_1D']\n",
    "U_num_params: [2, 10, 10, 2, 6, 6, 4, 6, 15, 15, 15, 2]\n",
    "Encodings: ['resize256', 'pca8', 'autoencoder8', 'pca16-compact', 'autoencoder16-compact', 'pca32-1', 'autoencoder32-1',\n",
    "            'pca16-1', 'autoencoder16-1', 'pca30-1', 'autoencoder30-1', 'pca12-1', 'autoencoder12-1']\n",
    "dataset: 'mnist' or 'fashion_mnist'\n",
    "circuit: 'QCNN' or 'Hierarchical'\n",
    "cost_fn: 'mse' or 'cross_entropy'\n",
    "Note: when using 'mse' as cost_fn binary=\"True\" is recommended, when using 'cross_entropy' as cost_fn must be binary=\"False\".\n",
    "\"\"\"\n",
    "\n",
    "Unitaries = ['U_SU4', 'U_SU4_1D', 'U_SU4_no_pooling', 'U_9_1D']\n",
    "U_num_params = [15, 15, 15, 2]\n",
    "Encodings = ['resize256']\n",
    "dataset = 'mnist'\n",
    "classes = [0,1]\n",
    "binary = False\n",
    "cost_fn = 'cross_entropy'\n",
    "\n",
    "Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
    "#Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='Hierarchical', cost_fn=cost_fn, binary=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
